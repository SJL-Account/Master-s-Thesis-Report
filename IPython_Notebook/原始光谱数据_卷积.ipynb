{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-------------------基础工具------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import time\n",
    "import os\n",
    "#------------------sklearn-------------------------------\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import t_sne\n",
    "import  sklearn.learning_curve \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#------------------keras --------------------------------\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dropout\n",
    "import keras \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras import Sequential\n",
    "\n",
    "\n",
    "#-----------------xgboost----------------------------\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "#---------------------参数设置----------------------------\n",
    "%matplotlib inline\n",
    "#CPU还是GPU\n",
    "import copy\n",
    "namespace='原始特征抽样_卷积'\n",
    "name_path='原始特征抽样_卷积/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_kappa(y_true,y_pre):\n",
    "    p0=0\n",
    "    pe=0\n",
    "    confux_m=confusion_matrix(y_true,y_pre)\n",
    "    confux_m_sum=confux_m.sum()\n",
    "    for i in range(len(confux_m)):\n",
    "        p0+=confux_m[i][i]\n",
    "        pe+=((confux_m[:,i]).sum())*((confux_m[i,:]).sum())\n",
    "    p0=p0/confux_m_sum\n",
    "    pe=pe/(confux_m_sum*confux_m_sum)\n",
    "    kappa=(p0-pe)/(1-pe)\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_custom_1(data,columns,kernel,op='arg'):\n",
    "    columns=data.columns[2:-1].tolist()\n",
    "    label_img=data['type'].values.reshape(256,108)\n",
    "    for col in columns:\n",
    "        var_img=data[col].values.reshape(256,108)\n",
    "        con_var_img=np.zeros((258,110))\n",
    "        con_label_img=np.ndarray(shape=(258,110),dtype=np.int32)\n",
    "        con_label_img[:,:]=-1\n",
    "        con_re=np.zeros((256,108))\n",
    "        for i in range(256):\n",
    "            for j in range(108):\n",
    "                con_var_img[i+1][j+1]=var_img[i][j]\n",
    "                con_label_img[i+1][j+1]=label_img[i][j]\n",
    "        for i in range(1,257):\n",
    "            for j in range(1,109):\n",
    "                center=con_label_img[i][j]\n",
    "                label_map=con_label_img[i-1:i+2,j-1:j+2]\n",
    "                label_filter=(label_map==center)\n",
    "                \n",
    "                con_re[i-1][j-1]=(((con_var_img[i-1:i+2,j-1:j+2][label_filter])*(kernel[label_filter])).sum())\n",
    "                                 \n",
    "        if op=='arg':\n",
    "            data[col+'_arg']=con_re.flatten()\n",
    "        elif op=='var':\n",
    "            data[col+'_var']=con_re.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv_(data,columns,kernel):\n",
    "    for col in columns:\n",
    "        var_img=data[col].values.reshape(256,108)\n",
    "        data[col+'_arg']=scipy.signal.convolve2d(var_img,kernel,mode='same').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,y_true,y_pre,y_fit_pre,clf_name):\n",
    "\n",
    "\n",
    "    if  not (os.path.exists(name_path+clf_name)):\n",
    "\n",
    "        os.mkdir(name_path+clf_name)\n",
    "\n",
    "\n",
    "    pipline_fit_score['accuracy'].append(accuracy_score(y_true,y_fit_pre))\n",
    "\n",
    "    pipline_test_score['accuracy'].append(accuracy_score(y_true,y_pre))\n",
    "\n",
    "    kappas_['kappa'].append(calc_kappa(y_true,y_pre))\n",
    "\n",
    "    pipline_fit_test_score['fit-accuracy'].append(accuracy_score(y_true,y_fit_pre))\n",
    "\n",
    "    pipline_fit_test_score['test-accuracy'].append(accuracy_score(y_true,y_pre))\n",
    "\n",
    "    pd.DataFrame(confusion_matrix(y_true,y_pre),index=range(1,17),columns=range(1,17)).to_csv(name_path+clf_name+'/'+clf_name+'_confux_matrix.csv')  \n",
    "\n",
    "    Salinas_df5_raw[y_true!=y_pre][['row','col']].to_csv(name_path+clf_name+'/'+clf_name+'false_loc.csv',index=None,columns=None)\n",
    "\n",
    "    Salinas_df5_raw['pre_type']=y_pre\n",
    "    \n",
    "    #np.savetxt(clf_name+'_pre_label.grd', y_pre.reshape(256,108),fmt='%d')\n",
    "\n",
    "    Salinas_df5_raw[['row','col','pre_type']].to_csv( name_path+clf_name+'/'+clf_name+'_pre.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ouput2(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,clf_names):\n",
    "    \n",
    "    if not (os.path.exists(name_path+'统计量')):\n",
    "        \n",
    "        os.mkdir(name_path+'统计量')\n",
    "    \n",
    "    print('正在输出分类器准确率')\n",
    "\n",
    "    pd.DataFrame(pipline_fit_score,index=clf_names).sort_values(by='accuracy').to_csv(name_path+'统计量/'+clf_name+'fit_accuracy.csv')\n",
    "    pd.DataFrame(pipline_test_score,index=clf_names).sort_values(by='accuracy').to_csv(name_path+'统计量/'+clf_name+'test_accuracy.csv')\n",
    "    pd.DataFrame(pipline_fit_test_score,index=clf_names).to_csv(name_path+'统计量/'+clf_name+'fit_test_accuracy.csv')\n",
    "\n",
    "    print('正在输出kappa系数')\n",
    "\n",
    "    pd.DataFrame(kappas_,index=clf_names).sort_values(by='kappa').to_csv(name_path+'统计量/'+clf_name+'kappa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据的导入，切分，标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.ix._setitem_with_indexer((slice(None), indexer), value)\n",
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2294: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在计算..SalinasResize_FCwithRC_T10_F25.txt\n",
      "[[0.07925725 0.10583055 0.04284373]\n",
      " [0.15905754 0.27287974 0.14675456]\n",
      " [0.03912634 0.09123236 0.06301792]]\n",
      "正在计算..SalinasResize_FCwithRC_T11_F25.txt\n",
      "[[0.08182767 0.11354924 0.03276854]\n",
      " [0.13086722 0.34048163 0.1104749 ]\n",
      " [0.03055884 0.09445556 0.06501639]]\n",
      "正在计算..SalinasResize_FCwithRC_T12_F25.txt\n",
      "[[0.08625591 0.12252314 0.04263612]\n",
      " [0.12594262 0.27652138 0.12199548]\n",
      " [0.04040346 0.11373316 0.06998873]]\n",
      "正在计算..SalinasResize_FCwithRC_T13_F25.txt\n",
      "[[0.07998501 0.14546802 0.03677192]\n",
      " [0.11071258 0.30090946 0.09004871]\n",
      " [0.03263165 0.13236256 0.07111009]]\n",
      "正在计算..SalinasResize_FCwithRC_T14_F25.txt\n",
      "[[0.08381537 0.10856967 0.03553648]\n",
      " [0.16064156 0.27812794 0.13850202]\n",
      " [0.03062198 0.09630963 0.06787534]]\n",
      "正在计算..SalinasResize_FCwithRC_T15_F25.txt\n",
      "[[0.08131591 0.11850402 0.04569384]\n",
      " [0.14759741 0.26313052 0.12940927]\n",
      " [0.04504526 0.10157504 0.06772872]]\n",
      "正在计算..SalinasResize_FCwithRC_T1_F25.txt\n",
      "[[0.02672162 0.11132963 0.0400423 ]\n",
      " [0.13632015 0.42334703 0.11486479]\n",
      " [0.03944284 0.09262983 0.01530181]]\n",
      "正在计算..SalinasResize_FCwithRC_T2_F25.txt\n",
      "[[0.05585782 0.11664129 0.03142586]\n",
      " [0.12163348 0.39901459 0.10806802]\n",
      " [0.03051462 0.09509755 0.04174675]]\n",
      "正在计算..SalinasResize_FCwithRC_T3_F25.txt\n",
      "[[0.08751994 0.12703042 0.04751034]\n",
      " [0.13457365 0.23711773 0.13199151]\n",
      " [0.04711011 0.11439578 0.07275051]]\n",
      "正在计算..SalinasResize_FCwithRC_T4_F25.txt\n",
      "[[0.078259   0.11247277 0.03191869]\n",
      " [0.14073564 0.31586246 0.13021352]\n",
      " [0.02969647 0.09708473 0.06375672]]\n",
      "正在计算..SalinasResize_FCwithRC_T5_F25.txt\n",
      "[[0.07117847 0.12462193 0.04971485]\n",
      " [0.12276929 0.30532045 0.11197285]\n",
      " [0.050041   0.10744444 0.05693672]]\n",
      "正在计算..SalinasResize_FCwithRC_T6_F25.txt\n",
      "[[0.0751284  0.10917231 0.048756  ]\n",
      " [0.14624376 0.29104855 0.12922753]\n",
      " [0.04738362 0.0928687  0.06017113]]\n",
      "正在计算..SalinasResize_FCwithRC_T7_F25.txt\n",
      "[[0.07204285 0.1141196  0.04951211]\n",
      " [0.1483941  0.27380743 0.13631139]\n",
      " [0.0499259  0.09676233 0.05912427]]\n",
      "正在计算..SalinasResize_FCwithRC_T8_F25.txt\n",
      "[[0.08929218 0.11297084 0.03783202]\n",
      " [0.13255678 0.30011699 0.12035028]\n",
      " [0.03583288 0.10050362 0.0705444 ]]\n",
      "正在计算..SalinasResize_FCwithRC_T9_F25.txt\n",
      "[[0.06445764 0.12526137 0.03207744]\n",
      " [0.14348042 0.32187528 0.12525626]\n",
      " [0.03195471 0.10894309 0.0466938 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25d81a65518>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD/CAYAAAAOoUbCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25dfeadb978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Salinas_df4_raw=pd.read_csv('Salinas_bandselect/SalinasResize_FCwithRC_No_4.txt',delimiter='\\t',index_col=False)\n",
    "Salinas_df5_raw=pd.read_csv('Salinas_bandselect/SalinasResize_FCwithRC_No_5.txt',delimiter='\\t',index_col=False)\n",
    "df4_columns=Salinas_df4_raw.columns[2:-1].tolist()\n",
    "df5_columns=Salinas_df5_raw.columns[2:-1].tolist()\n",
    "df4_arg_columns=[]\n",
    "df5_arg_columns=[]\n",
    "df4_var_columns=[]\n",
    "df5_var_columns=[]\n",
    "df4_var_var_columns=[]\n",
    "df5_var_var_columns=[]\n",
    "for col in df4_columns:\n",
    "    df4_arg_columns.append(col+'_arg')\n",
    "    Salinas_df4_raw[col+'_arg']=0\n",
    "for col in df5_columns:\n",
    "    df5_arg_columns.append(col+'_arg')\n",
    "    Salinas_df5_raw[col+'_arg']=0\n",
    "\n",
    "#---------------------------------------------------------\n",
    "dirs_=os.listdir('../变差函数feature_map/变差函数_25波段/')\n",
    "\n",
    "for dir_ in dirs_:\n",
    "    print('正在计算..'+dir_)\n",
    "    deviation=np.loadtxt('../变差函数feature_map/变差函数_25波段/'+dir_)\n",
    "\n",
    "    deviation_=np.zeros((42,42))\n",
    "    deviation_[:-1,:-1]=deviation\n",
    "    deviation_sum=deviation_.sum()\n",
    "    conv_matrix=np.zeros((3,3))\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            conv_matrix[i,j]=((deviation_[i*14:(i+1)*14,j*14:(j+1)*14]).sum())/deviation_sum\n",
    "\n",
    "    kernel=conv_matrix\n",
    "    print(kernel)\n",
    "    Type=int(dir_[-9])\n",
    "    \n",
    "    #创建列\n",
    "\n",
    "    #复制数据\n",
    "    Salinas_df4_temp=copy.deepcopy(Salinas_df4_raw)\n",
    "    Salinas_df5_temp=copy.deepcopy(Salinas_df5_raw)\n",
    "    \n",
    "    #做成除了该类型外其他类型的光谱强度均为0的情况，Featuremap\n",
    "    Salinas_df4_temp[Salinas_df4_temp['type']!=Type][df4_columns]=0\n",
    "    Salinas_df5_temp[Salinas_df5_temp['type']!=Type][df5_columns]=0\n",
    "    #获取对应的index\n",
    "    indexs_4=Salinas_df4_temp[Salinas_df4_temp['type']==Type].index\n",
    "    indexs_5=Salinas_df5_temp[Salinas_df5_temp['type']==Type].index\n",
    "    \n",
    "    #卷积操作\n",
    "    conv_(Salinas_df4_temp,df4_columns,kernel)\n",
    "    conv_(Salinas_df5_temp,df5_columns,kernel)\n",
    "   \n",
    "    \n",
    "    #对应类型对应列进行复制\n",
    "    Salinas_df4_raw.ix[indexs_4,df4_arg_columns]=Salinas_df4_temp.ix[indexs_4,df4_arg_columns]\n",
    "    Salinas_df5_raw.ix[indexs_5,df5_arg_columns]=Salinas_df5_temp.ix[indexs_5,df5_arg_columns]\n",
    "#----------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "Salinas_df4_raw=Salinas_df4_raw[Salinas_df4_raw.type!=0]\n",
    "Salinas_df5_raw=Salinas_df5_raw[Salinas_df5_raw.type!=0]\n",
    "Salinas_df4=copy.deepcopy(Salinas_df4_raw)\n",
    "Salinas_df5=copy.deepcopy(Salinas_df5_raw)\n",
    "std=StandardScaler()\n",
    "Salinas_df4.pop('row')\n",
    "Salinas_df4.pop('col')\n",
    "y_train=Salinas_df4.pop('type')\n",
    "x_train=Salinas_df4\n",
    "x_train=std.fit_transform(x_train)\n",
    "Salinas_df5.pop('row')\n",
    "Salinas_df5.pop('col')\n",
    "y_test=Salinas_df5.pop('type')\n",
    "x_test=Salinas_df5\n",
    "x_test=std.fit_transform(x_test)\n",
    "y_true=y_test\n",
    "y_train.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "拟合 逻辑回归 0.9828020756115641\n",
      "测试 逻辑回归 0.9790956263899184\n",
      "拟合 梯度提升决策树 1.0\n",
      "测试 梯度提升决策树 0.9909562638991846\n",
      "拟合 随机森林 0.9997034840622684\n",
      "测试 随机森林 0.994885100074129\n",
      "拟合 决策树 1.0\n",
      "测试 决策树 0.9681986656782802\n",
      "拟合 K-临近 0.9931801334321719\n",
      "测试 K-临近 0.9925129725722758\n",
      "拟合 SVM 0.9867309117865085\n",
      "测试 SVM 0.9851000741289845\n",
      "正在输出分类器准确率\n",
      "正在输出kappa系数\n"
     ]
    }
   ],
   "source": [
    "if not (os.path.exists(namespace)):\n",
    "    os.mkdir(namespace)\n",
    "\n",
    "piplines=[LogisticRegression(),GradientBoostingClassifier(),RandomForestClassifier(),DecisionTreeClassifier(),KNeighborsClassifier(),SVC()]\n",
    "pipline_fit_score={'accuracy':[]}\n",
    "pipline_test_score={'accuracy':[]}\n",
    "pipline_fit_test_score={'fit-accuracy':[],'test-accuracy':[]}\n",
    "kappas_={'kappa':[]}\n",
    "\n",
    "clf_names=['逻辑回归','梯度提升决策树','随机森林','决策树','K-临近','SVM']\n",
    "\n",
    "for clf_name,clf in zip(clf_names,piplines):\n",
    "    \n",
    "    \n",
    "    clf.fit(x_train,y_train)\n",
    "    \n",
    "    print('拟合',clf_name,clf.score(x_train,y_train))\n",
    "    \n",
    "    print('测试',clf_name,clf.score(x_test,y_test))\n",
    "    \n",
    "    y_fit_pre=clf.predict(x_train)\n",
    "\n",
    "    y_pre=clf.predict(x_test)\n",
    "    \n",
    "    output(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,y_true,y_pre,y_fit_pre,clf_name)\n",
    "\n",
    "ouput2(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,clf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.009414\ttest-merror:0.017198\n",
      "[100]\ttrain-merror:7.4e-05\ttest-merror:0.008154\n",
      "[200]\ttrain-merror:0\ttest-merror:0.007932\n",
      "[300]\ttrain-merror:0\ttest-merror:0.008006\n",
      "[399]\ttrain-merror:0\ttest-merror:0.008006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9919940696812454"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_data_train=xgb.DMatrix(x_train,label=y_train)\n",
    "xgb_data_test=xgb.DMatrix(x_test,label=y_test)\n",
    "params={'max_depth':10,'eta':0.1,'silent':0,'objective':'multi:softmax','num_class':17,'alpha':0.5}\n",
    "bst=xgb.train(params, \n",
    "          xgb_data_train, \n",
    "          num_boost_round=400, \n",
    "          evals=[(xgb_data_train,'train'),(xgb_data_test,'test')], \n",
    "          obj=None, \n",
    "          feval=None, \n",
    "          maximize=False, \n",
    "          early_stopping_rounds=None,\n",
    "          evals_result=None,\n",
    "          verbose_eval=100,\n",
    "          xgb_model=None,\n",
    "          callbacks=None)\n",
    "xgb_data_test=xgb.DMatrix(x_test)\n",
    "y_pre=bst.predict(xgb_data_test)\n",
    "y_true=y_test\n",
    "\n",
    "y_pre=bst.predict(xgb_data_test)\n",
    "y_fit_pre=bst.predict(xgb_data_train)\n",
    "y_true=y_test\n",
    "accuracy_score(y_true,y_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在输出分类器准确率\n",
      "正在输出kappa系数\n"
     ]
    }
   ],
   "source": [
    "clf_name='XGBoost'\n",
    "clf_names.append(clf_name)\n",
    "output(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,y_true,y_pre,y_fit_pre,clf_name)\n",
    "ouput2(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,clf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(16, 48), b.shape=(48, 288), m=16, n=288, k=48\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, _class=[\"loc:@training/SGD/gradients/dense_1/MatMul_grad/MatMul_1\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_dense_1_input_0_0/_29, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_49 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_221_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c266fc8ceb15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0my_pre\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[1;32m-> 1454\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(16, 48), b.shape=(48, 288), m=16, n=288, k=48\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, _class=[\"loc:@training/SGD/gradients/dense_1/MatMul_grad/MatMul_1\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_dense_1_input_0_0/_29, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_49 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_221_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "i=6\n",
    "input_dim=x_train.shape[1]\n",
    "output_dim=len(set(y_train.tolist()))\n",
    "batch_size=16\n",
    "lr=0.1\n",
    "epochs=50\n",
    "hidden_num = input_dim*i\n",
    "hidden_num_2 = output_dim*i\n",
    "ohe = OneHotEncoder()\n",
    "y_train=ohe.fit_transform(np.matrix(y_train.values).T).toarray()\n",
    "model=Sequential()\n",
    "model.add(Dense(input_dim=input_dim,units=hidden_num))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(input_dim=hidden_num_2,units=output_dim))\n",
    "optimizer=SGD(lr=lr)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)\n",
    "model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,verbose=1)\n",
    "\n",
    "y_pre=model.predict_classes(x_test, batch_size=batch_size)\n",
    "y_fit_pre=model.predict_classes(x_train, batch_size=batch_size)\n",
    "\n",
    "y_true=y_test\n",
    "y_pre=y_pre+1\n",
    "y_fit_pre=y_fit_pre+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_name='NN'\n",
    "clf_names.append(clf_name)\n",
    "output(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,y_true,y_pre,y_fit_pre,clf_name)\n",
    "ouput2(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,clf_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉矩阵(准确率、召回率,F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kappa系数\n",
    "准确率\n",
    "kappa计算结果为-1~1，但通常kappa是落在 0~1 间，可分为五组来表示不同级别的一致性：\n",
    "0.0~0.20极低的一致性(slight)、\n",
    "0.21~0.40一般的一致性(fair)、\n",
    "0.41~0.60 中等的一致性(moderate)、\n",
    "0.61~0.80 高度的一致性(substantial)\n",
    "0.81~1几乎完全一致(almost perfect)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losss下降过程(运算时间)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "错的点的坐标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测值的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络层数图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
