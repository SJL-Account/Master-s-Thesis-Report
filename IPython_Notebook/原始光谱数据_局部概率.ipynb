{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-------------------基础工具------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import time\n",
    "import os\n",
    "#------------------sklearn-------------------------------\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import t_sne\n",
    "import  sklearn.learning_curve \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#------------------keras --------------------------------\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dropout\n",
    "import keras \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras import Sequential\n",
    "\n",
    "\n",
    "#-----------------xgboost----------------------------\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "#---------------------参数设置----------------------------\n",
    "%matplotlib inline\n",
    "#CPU还是GPU\n",
    "import copy\n",
    "namespace='原始特征抽样_局部概率'\n",
    "name_path='原始特征抽样_局部概率/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_kappa(y_true,y_pre):\n",
    "    p0=0\n",
    "    pe=0\n",
    "    confux_m=confusion_matrix(y_true,y_pre)\n",
    "    confux_m_sum=confux_m.sum()\n",
    "    for i in range(len(confux_m)):\n",
    "        p0+=confux_m[i][i]\n",
    "        pe+=((confux_m[:,i]).sum())*((confux_m[i,:]).sum())\n",
    "    p0=p0/confux_m_sum\n",
    "    pe=pe/(confux_m_sum*confux_m_sum)\n",
    "    kappa=(p0-pe)/(1-pe)\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_custom_1(data,columns,kernel,op='arg'):\n",
    "    label_img=data['type'].values.reshape(256,108)\n",
    "    for col in columns:\n",
    "        var_img=data[col].values.reshape(256,108)\n",
    "        con_var_img=np.zeros((258,110))\n",
    "        con_label_img=np.ndarray(shape=(258,110),dtype=np.int32)\n",
    "        con_label_img[:,:]=-1\n",
    "        con_re=np.zeros((256,108))\n",
    "        for i in range(256):\n",
    "            for j in range(108):\n",
    "                con_var_img[i+1][j+1]=var_img[i][j]\n",
    "                con_label_img[i+1][j+1]=label_img[i][j]\n",
    "        for i in range(1,257):\n",
    "            for j in range(1,109):\n",
    "                center=con_label_img[i][j]\n",
    "                label_map=con_label_img[i-1:i+2,j-1:j+2]\n",
    "                label_filter=(label_map==center)\n",
    "                \n",
    "                if op=='arg':\n",
    "                    con_re[i-1][j-1]=con_var_img[i-1:i+2,j-1:j+2][label_filter].mean()\n",
    "                elif op=='var':\n",
    "                    con_re[i-1][j-1]=con_var_img[i-1:i+2,j-1:j+2][label_filter].var()\n",
    "        if op=='arg':\n",
    "            data[col+'_arg']=con_re.flatten()\n",
    "        elif op=='var':\n",
    "            data[col+'_var']=con_re.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv_(data,columns,kernel):\n",
    "    for col in columns:\n",
    "        var_img=data[col].values.reshape(256,108)\n",
    "        data[col+'_arg']=scipy.signal.convolve2d(var_img,kernel,mode='same').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_name='1'\n",
    "os.mkdir(name_path+clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,y_true,y_pre,y_fit_pre,clf_name):\n",
    "\n",
    "\n",
    "    if  not (os.path.exists(name_path+clf_name)):\n",
    "\n",
    "        os.mkdir(name_path+clf_name)\n",
    "\n",
    "\n",
    "    pipline_fit_score['accuracy'].append(accuracy_score(y_true,y_fit_pre))\n",
    "\n",
    "    pipline_test_score['accuracy'].append(accuracy_score(y_true,y_pre))\n",
    "\n",
    "    kappas_['kappa'].append(calc_kappa(y_true,y_pre))\n",
    "\n",
    "    pipline_fit_test_score['fit-accuracy'].append(accuracy_score(y_true,y_fit_pre))\n",
    "\n",
    "    pipline_fit_test_score['test-accuracy'].append(accuracy_score(y_true,y_pre))\n",
    "\n",
    "    pd.DataFrame(confusion_matrix(y_true,y_pre),index=range(1,17),columns=range(1,17)).to_csv(name_path+clf_name+'/'+clf_name+'_confux_matrix.csv')  \n",
    "\n",
    "    Salinas_df5_raw[y_true!=y_pre][['row','col']].to_csv(name_path+clf_name+'/'+clf_name+'false_loc.csv',index=None,columns=None)\n",
    "\n",
    "    Salinas_df5_raw['pre_type']=y_pre\n",
    "    \n",
    "    #np.savetxt(clf_name+'_pre_label.grd', y_pre.reshape(256,108),fmt='%d')\n",
    "\n",
    "    Salinas_df5_raw[['row','col','pre_type']].to_csv( name_path+clf_name+'/'+clf_name+'_pre.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ouput2(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,clf_names):\n",
    "    \n",
    "    if not (os.path.exists(name_path+'统计量')):\n",
    "        \n",
    "        os.mkdir(name_path+'统计量')\n",
    "    \n",
    "    print('正在输出分类器准确率')\n",
    "\n",
    "    pd.DataFrame(pipline_fit_score,index=clf_names).sort_values(by='accuracy').to_csv(name_path+'统计量/'+clf_name+'fit_accuracy.csv')\n",
    "    pd.DataFrame(pipline_test_score,index=clf_names).sort_values(by='accuracy').to_csv(name_path+'统计量/'+clf_name+'test_accuracy.csv')\n",
    "    pd.DataFrame(pipline_fit_test_score,index=clf_names).to_csv(name_path+'统计量/'+clf_name+'fit_test_accuracy.csv')\n",
    "\n",
    "    print('正在输出kappa系数')\n",
    "\n",
    "    pd.DataFrame(kappas_,index=clf_names).sort_values(by='kappa').to_csv(name_path+'统计量/'+clf_name+'kappa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据的导入，切分，标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集维度： (27648, 27) 训练集变量: ['V4', 'V12', 'V20', 'V28', 'V36', 'V44', 'V52', 'V60', 'V68', 'V76', 'V84', 'V92', 'V100', 'V108', 'V116', 'V124', 'V132', 'V140', 'V148', 'V156', 'V164', 'V172', 'V180', 'V188']\n",
      "测试集维度： (27648, 27) 测试集变量: ['V5', 'V13', 'V21', 'V29', 'V37', 'V45', 'V53', 'V61', 'V69', 'V77', 'V85', 'V93', 'V101', 'V109', 'V117', 'V125', 'V133', 'V141', 'V149', 'V157', 'V165', 'V173', 'V181', 'V189']\n",
      "1 V4\n",
      "1 V12\n",
      "1 V20\n",
      "1 V28\n",
      "1 V36\n",
      "1 V44\n",
      "1 V52\n",
      "1 V60\n",
      "1 V68\n",
      "1 V76\n",
      "1 V84\n",
      "1 V92\n",
      "1 V100\n",
      "1 V108\n",
      "1 V116\n",
      "1 V124\n",
      "1 V132\n",
      "1 V140\n",
      "1 V148\n",
      "1 V156\n",
      "1 V164\n",
      "1 V172\n",
      "1 V180\n",
      "1 V188\n",
      "1 V5\n",
      "1 V13\n",
      "1 V21\n",
      "1 V29\n",
      "1 V37\n",
      "1 V45\n",
      "1 V53\n",
      "1 V61\n",
      "1 V69\n",
      "1 V77\n",
      "1 V85\n",
      "1 V93\n",
      "1 V101\n",
      "1 V109\n",
      "1 V117\n",
      "1 V125\n",
      "1 V133\n",
      "1 V141\n",
      "1 V149\n",
      "1 V157\n",
      "1 V165\n",
      "1 V173\n",
      "1 V181\n",
      "1 V189\n",
      "2 V4\n",
      "2 V12\n",
      "2 V20\n",
      "2 V28\n",
      "2 V36\n",
      "2 V44\n",
      "2 V52\n",
      "2 V60\n",
      "2 V68\n",
      "2 V76\n",
      "2 V84\n",
      "2 V92\n",
      "2 V100\n",
      "2 V108\n",
      "2 V116\n",
      "2 V124\n",
      "2 V132\n",
      "2 V140\n",
      "2 V148\n",
      "2 V156\n",
      "2 V164\n",
      "2 V172\n",
      "2 V180\n",
      "2 V188\n",
      "2 V5\n",
      "2 V13\n",
      "2 V21\n",
      "2 V29\n",
      "2 V37\n",
      "2 V45\n",
      "2 V53\n",
      "2 V61\n",
      "2 V69\n",
      "2 V77\n",
      "2 V85\n",
      "2 V93\n",
      "2 V101\n",
      "2 V109\n",
      "2 V117\n",
      "2 V125\n",
      "2 V133\n",
      "2 V141\n",
      "2 V149\n",
      "2 V157\n",
      "2 V165\n",
      "2 V173\n",
      "2 V181\n",
      "2 V189\n",
      "3 V4\n",
      "3 V12\n",
      "3 V20\n",
      "3 V28\n",
      "3 V36\n",
      "3 V44\n",
      "3 V52\n",
      "3 V60\n",
      "3 V68\n",
      "3 V76\n",
      "3 V84\n",
      "3 V92\n",
      "3 V100\n",
      "3 V108\n",
      "3 V116\n",
      "3 V124\n",
      "3 V132\n",
      "3 V140\n",
      "3 V148\n",
      "3 V156\n",
      "3 V164\n",
      "3 V172\n",
      "3 V180\n",
      "3 V188\n",
      "3 V5\n",
      "3 V13\n",
      "3 V21\n",
      "3 V29\n",
      "3 V37\n",
      "3 V45\n",
      "3 V53\n",
      "3 V61\n",
      "3 V69\n",
      "3 V77\n",
      "3 V85\n",
      "3 V93\n",
      "3 V101\n",
      "3 V109\n",
      "3 V117\n",
      "3 V125\n",
      "3 V133\n",
      "3 V141\n",
      "3 V149\n",
      "3 V157\n",
      "3 V165\n",
      "3 V173\n",
      "3 V181\n",
      "3 V189\n",
      "4 V4\n",
      "4 V12\n",
      "4 V20\n",
      "4 V28\n",
      "4 V36\n",
      "4 V44\n",
      "4 V52\n",
      "4 V60\n",
      "4 V68\n",
      "4 V76\n",
      "4 V84\n",
      "4 V92\n",
      "4 V100\n",
      "4 V108\n",
      "4 V116\n",
      "4 V124\n",
      "4 V132\n",
      "4 V140\n",
      "4 V148\n",
      "4 V156\n",
      "4 V164\n",
      "4 V172\n",
      "4 V180\n",
      "4 V188\n",
      "4 V5\n",
      "4 V13\n",
      "4 V21\n",
      "4 V29\n",
      "4 V37\n",
      "4 V45\n",
      "4 V53\n",
      "4 V61\n",
      "4 V69\n",
      "4 V77\n",
      "4 V85\n",
      "4 V93\n",
      "4 V101\n",
      "4 V109\n",
      "4 V117\n",
      "4 V125\n",
      "4 V133\n",
      "4 V141\n",
      "4 V149\n",
      "4 V157\n",
      "4 V165\n",
      "4 V173\n",
      "4 V181\n",
      "4 V189\n",
      "5 V4\n",
      "5 V12\n",
      "5 V20\n",
      "5 V28\n",
      "5 V36\n",
      "5 V44\n",
      "5 V52\n",
      "5 V60\n",
      "5 V68\n",
      "5 V76\n",
      "5 V84\n",
      "5 V92\n",
      "5 V100\n",
      "5 V108\n",
      "5 V116\n",
      "5 V124\n",
      "5 V132\n",
      "5 V140\n",
      "5 V148\n",
      "5 V156\n",
      "5 V164\n",
      "5 V172\n",
      "5 V180\n",
      "5 V188\n",
      "5 V5\n",
      "5 V13\n",
      "5 V21\n",
      "5 V29\n",
      "5 V37\n",
      "5 V45\n",
      "5 V53\n",
      "5 V61\n",
      "5 V69\n",
      "5 V77\n",
      "5 V85\n",
      "5 V93\n",
      "5 V101\n",
      "5 V109\n",
      "5 V117\n",
      "5 V125\n",
      "5 V133\n",
      "5 V141\n",
      "5 V149\n",
      "5 V157\n",
      "5 V165\n",
      "5 V173\n",
      "5 V181\n",
      "5 V189\n",
      "6 V4\n",
      "6 V12\n",
      "6 V20\n",
      "6 V28\n",
      "6 V36\n",
      "6 V44\n",
      "6 V52\n",
      "6 V60\n",
      "6 V68\n",
      "6 V76\n",
      "6 V84\n",
      "6 V92\n",
      "6 V100\n",
      "6 V108\n",
      "6 V116\n",
      "6 V124\n",
      "6 V132\n",
      "6 V140\n",
      "6 V148\n",
      "6 V156\n",
      "6 V164\n",
      "6 V172\n",
      "6 V180\n",
      "6 V188\n",
      "6 V5\n",
      "6 V13\n",
      "6 V21\n",
      "6 V29\n",
      "6 V37\n",
      "6 V45\n",
      "6 V53\n",
      "6 V61\n",
      "6 V69\n",
      "6 V77\n",
      "6 V85\n",
      "6 V93\n",
      "6 V101\n",
      "6 V109\n",
      "6 V117\n",
      "6 V125\n",
      "6 V133\n",
      "6 V141\n",
      "6 V149\n",
      "6 V157\n",
      "6 V165\n",
      "6 V173\n",
      "6 V181\n",
      "6 V189\n",
      "7 V4\n",
      "7 V12\n",
      "7 V20\n",
      "7 V28\n",
      "7 V36\n",
      "7 V44\n",
      "7 V52\n",
      "7 V60\n",
      "7 V68\n",
      "7 V76\n",
      "7 V84\n",
      "7 V92\n",
      "7 V100\n",
      "7 V108\n",
      "7 V116\n",
      "7 V124\n",
      "7 V132\n",
      "7 V140\n",
      "7 V148\n",
      "7 V156\n",
      "7 V164\n",
      "7 V172\n",
      "7 V180\n",
      "7 V188\n",
      "7 V5\n",
      "7 V13\n",
      "7 V21\n",
      "7 V29\n",
      "7 V37\n",
      "7 V45\n",
      "7 V53\n",
      "7 V61\n",
      "7 V69\n",
      "7 V77\n",
      "7 V85\n",
      "7 V93\n",
      "7 V101\n",
      "7 V109\n",
      "7 V117\n",
      "7 V125\n",
      "7 V133\n",
      "7 V141\n",
      "7 V149\n",
      "7 V157\n",
      "7 V165\n",
      "7 V173\n",
      "7 V181\n",
      "7 V189\n",
      "8 V4\n",
      "8 V12\n",
      "8 V20\n",
      "8 V28\n",
      "8 V36\n",
      "8 V44\n",
      "8 V52\n",
      "8 V60\n",
      "8 V68\n",
      "8 V76\n",
      "8 V84\n",
      "8 V92\n",
      "8 V100\n",
      "8 V108\n",
      "8 V116\n",
      "8 V124\n",
      "8 V132\n",
      "8 V140\n",
      "8 V148\n",
      "8 V156\n",
      "8 V164\n",
      "8 V172\n",
      "8 V180\n",
      "8 V188\n",
      "8 V5\n",
      "8 V13\n",
      "8 V21\n",
      "8 V29\n",
      "8 V37\n",
      "8 V45\n",
      "8 V53\n",
      "8 V61\n",
      "8 V69\n",
      "8 V77\n",
      "8 V85\n",
      "8 V93\n",
      "8 V101\n",
      "8 V109\n",
      "8 V117\n",
      "8 V125\n",
      "8 V133\n",
      "8 V141\n",
      "8 V149\n",
      "8 V157\n",
      "8 V165\n",
      "8 V173\n",
      "8 V181\n",
      "8 V189\n",
      "9 V4\n",
      "9 V12\n",
      "9 V20\n",
      "9 V28\n",
      "9 V36\n",
      "9 V44\n",
      "9 V52\n",
      "9 V60\n",
      "9 V68\n",
      "9 V76\n",
      "9 V84\n",
      "9 V92\n",
      "9 V100\n",
      "9 V108\n",
      "9 V116\n",
      "9 V124\n",
      "9 V132\n",
      "9 V140\n",
      "9 V148\n",
      "9 V156\n",
      "9 V164\n",
      "9 V172\n",
      "9 V180\n",
      "9 V188\n",
      "9 V5\n",
      "9 V13\n",
      "9 V21\n",
      "9 V29\n",
      "9 V37\n",
      "9 V45\n",
      "9 V53\n",
      "9 V61\n",
      "9 V69\n",
      "9 V77\n",
      "9 V85\n",
      "9 V93\n",
      "9 V101\n",
      "9 V109\n",
      "9 V117\n",
      "9 V125\n",
      "9 V133\n",
      "9 V141\n",
      "9 V149\n",
      "9 V157\n",
      "9 V165\n",
      "9 V173\n",
      "9 V181\n",
      "9 V189\n",
      "10 V4\n",
      "10 V12\n",
      "10 V20\n",
      "10 V28\n",
      "10 V36\n",
      "10 V44\n",
      "10 V52\n",
      "10 V60\n",
      "10 V68\n",
      "10 V76\n",
      "10 V84\n",
      "10 V92\n",
      "10 V100\n",
      "10 V108\n",
      "10 V116\n",
      "10 V124\n",
      "10 V132\n",
      "10 V140\n",
      "10 V148\n",
      "10 V156\n",
      "10 V164\n",
      "10 V172\n",
      "10 V180\n",
      "10 V188\n",
      "10 V5\n",
      "10 V13\n",
      "10 V21\n",
      "10 V29\n",
      "10 V37\n",
      "10 V45\n",
      "10 V53\n",
      "10 V61\n",
      "10 V69\n",
      "10 V77\n",
      "10 V85\n",
      "10 V93\n",
      "10 V101\n",
      "10 V109\n",
      "10 V117\n",
      "10 V125\n",
      "10 V133\n",
      "10 V141\n",
      "10 V149\n",
      "10 V157\n",
      "10 V165\n",
      "10 V173\n",
      "10 V181\n",
      "10 V189\n",
      "11 V4\n",
      "11 V12\n",
      "11 V20\n",
      "11 V28\n",
      "11 V36\n",
      "11 V44\n",
      "11 V52\n",
      "11 V60\n",
      "11 V68\n",
      "11 V76\n",
      "11 V84\n",
      "11 V92\n",
      "11 V100\n",
      "11 V108\n",
      "11 V116\n",
      "11 V124\n",
      "11 V132\n",
      "11 V140\n",
      "11 V148\n",
      "11 V156\n",
      "11 V164\n",
      "11 V172\n",
      "11 V180\n",
      "11 V188\n",
      "11 V5\n",
      "11 V13\n",
      "11 V21\n",
      "11 V29\n",
      "11 V37\n",
      "11 V45\n",
      "11 V53\n",
      "11 V61\n",
      "11 V69\n",
      "11 V77\n",
      "11 V85\n",
      "11 V93\n",
      "11 V101\n",
      "11 V109\n",
      "11 V117\n",
      "11 V125\n",
      "11 V133\n",
      "11 V141\n",
      "11 V149\n",
      "11 V157\n",
      "11 V165\n",
      "11 V173\n",
      "11 V181\n",
      "11 V189\n",
      "12 V4\n",
      "12 V12\n",
      "12 V20\n",
      "12 V28\n",
      "12 V36\n",
      "12 V44\n",
      "12 V52\n",
      "12 V60\n",
      "12 V68\n",
      "12 V76\n",
      "12 V84\n",
      "12 V92\n",
      "12 V100\n",
      "12 V108\n",
      "12 V116\n",
      "12 V124\n",
      "12 V132\n",
      "12 V140\n",
      "12 V148\n",
      "12 V156\n",
      "12 V164\n",
      "12 V172\n",
      "12 V180\n",
      "12 V188\n",
      "12 V5\n",
      "12 V13\n",
      "12 V21\n",
      "12 V29\n",
      "12 V37\n",
      "12 V45\n",
      "12 V53\n",
      "12 V61\n",
      "12 V69\n",
      "12 V77\n",
      "12 V85\n",
      "12 V93\n",
      "12 V101\n",
      "12 V109\n",
      "12 V117\n",
      "12 V125\n",
      "12 V133\n",
      "12 V141\n",
      "12 V149\n",
      "12 V157\n",
      "12 V165\n",
      "12 V173\n",
      "12 V181\n",
      "12 V189\n",
      "13 V4\n",
      "13 V12\n",
      "13 V20\n",
      "13 V28\n",
      "13 V36\n",
      "13 V44\n",
      "13 V52\n",
      "13 V60\n",
      "13 V68\n",
      "13 V76\n",
      "13 V84\n",
      "13 V92\n",
      "13 V100\n",
      "13 V108\n",
      "13 V116\n",
      "13 V124\n",
      "13 V132\n",
      "13 V140\n",
      "13 V148\n",
      "13 V156\n",
      "13 V164\n",
      "13 V172\n",
      "13 V180\n",
      "13 V188\n",
      "13 V5\n",
      "13 V13\n",
      "13 V21\n",
      "13 V29\n",
      "13 V37\n",
      "13 V45\n",
      "13 V53\n",
      "13 V61\n",
      "13 V69\n",
      "13 V77\n",
      "13 V85\n",
      "13 V93\n",
      "13 V101\n",
      "13 V109\n",
      "13 V117\n",
      "13 V125\n",
      "13 V133\n",
      "13 V141\n",
      "13 V149\n",
      "13 V157\n",
      "13 V165\n",
      "13 V173\n",
      "13 V181\n",
      "13 V189\n",
      "14 V4\n",
      "14 V12\n",
      "14 V20\n",
      "14 V28\n",
      "14 V36\n",
      "14 V44\n",
      "14 V52\n",
      "14 V60\n",
      "14 V68\n",
      "14 V76\n",
      "14 V84\n",
      "14 V92\n",
      "14 V100\n",
      "14 V108\n",
      "14 V116\n",
      "14 V124\n",
      "14 V132\n",
      "14 V140\n",
      "14 V148\n",
      "14 V156\n",
      "14 V164\n",
      "14 V172\n",
      "14 V180\n",
      "14 V188\n",
      "14 V5\n",
      "14 V13\n",
      "14 V21\n",
      "14 V29\n",
      "14 V37\n",
      "14 V45\n",
      "14 V53\n",
      "14 V61\n",
      "14 V69\n",
      "14 V77\n",
      "14 V85\n",
      "14 V93\n",
      "14 V101\n",
      "14 V109\n",
      "14 V117\n",
      "14 V125\n",
      "14 V133\n",
      "14 V141\n",
      "14 V149\n",
      "14 V157\n",
      "14 V165\n",
      "14 V173\n",
      "14 V181\n",
      "14 V189\n",
      "15 V4\n",
      "15 V12\n",
      "15 V20\n",
      "15 V28\n",
      "15 V36\n",
      "15 V44\n",
      "15 V52\n",
      "15 V60\n",
      "15 V68\n",
      "15 V76\n",
      "15 V84\n",
      "15 V92\n",
      "15 V100\n",
      "15 V108\n",
      "15 V116\n",
      "15 V124\n",
      "15 V132\n",
      "15 V140\n",
      "15 V148\n",
      "15 V156\n",
      "15 V164\n",
      "15 V172\n",
      "15 V180\n",
      "15 V188\n",
      "15 V5\n",
      "15 V13\n",
      "15 V21\n",
      "15 V29\n",
      "15 V37\n",
      "15 V45\n",
      "15 V53\n",
      "15 V61\n",
      "15 V69\n",
      "15 V77\n",
      "15 V85\n",
      "15 V93\n",
      "15 V101\n",
      "15 V109\n",
      "15 V117\n",
      "15 V125\n",
      "15 V133\n",
      "15 V141\n",
      "15 V149\n",
      "15 V157\n",
      "15 V165\n",
      "15 V173\n",
      "15 V181\n",
      "15 V189\n",
      "16 V4\n",
      "16 V12\n",
      "16 V20\n",
      "16 V28\n",
      "16 V36\n",
      "16 V44\n",
      "16 V52\n",
      "16 V60\n",
      "16 V68\n",
      "16 V76\n",
      "16 V84\n",
      "16 V92\n",
      "16 V100\n",
      "16 V108\n",
      "16 V116\n",
      "16 V124\n",
      "16 V132\n",
      "16 V140\n",
      "16 V148\n",
      "16 V156\n",
      "16 V164\n",
      "16 V172\n",
      "16 V180\n",
      "16 V188\n",
      "16 V5\n",
      "16 V13\n",
      "16 V21\n",
      "16 V29\n",
      "16 V37\n",
      "16 V45\n",
      "16 V53\n",
      "16 V61\n",
      "16 V69\n",
      "16 V77\n",
      "16 V85\n",
      "16 V93\n",
      "16 V101\n",
      "16 V109\n",
      "16 V117\n",
      "16 V125\n",
      "16 V133\n",
      "16 V141\n",
      "16 V149\n",
      "16 V157\n",
      "16 V165\n",
      "16 V173\n",
      "16 V181\n",
      "16 V189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19bcc6b94e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD/CAYAAAAOoUbCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19bcc6de9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Salinas_df4_raw=pd.read_csv('Salinas_bandselect/SalinasResize_FCwithRC_No_4.txt',delimiter='\\t',index_col=False)\n",
    "Salinas_df5_raw=pd.read_csv('Salinas_bandselect/SalinasResize_FCwithRC_No_5.txt',delimiter='\\t',index_col=False)\n",
    "df4_columns=Salinas_df4_raw.columns[2:-1].tolist()\n",
    "df5_columns=Salinas_df5_raw.columns[2:-1].tolist()\n",
    "print('训练集维度：',Salinas_df4_raw.shape,'训练集变量:',df4_columns)\n",
    "print('测试集维度：',Salinas_df5_raw.shape,'测试集变量:',df5_columns)\n",
    "\n",
    "#---------------------------------------------------------\n",
    "label_img=np.ndarray(shape=(258,110),dtype=np.int32)\n",
    "label_img[:,:]=-1\n",
    "type_m=Salinas_df4_raw.type.reshape(256,108)\n",
    "label_img[1:257,1:109]=type_m\n",
    "\n",
    "for k in range(1,17):\n",
    "    \n",
    "    type_prob_m=(label_img==k).astype('int32')/9\n",
    "\n",
    "    for col in df4_columns:\n",
    "        print(k,col)\n",
    "        con_var_img=np.zeros((258,110))\n",
    "        con_var_img[1:257,1:109]=Salinas_df4_raw[col].reshape(256,108)\n",
    "        con_re=np.zeros((256,108))\n",
    "        for i in range(1,257):\n",
    "            for j in range(1,109):\n",
    "                con_re[i-1][j-1]=(con_var_img[i-1:i+2,j-1:j+2]*type_prob_m[i-1:i+2,j-1:j+2]).sum()\n",
    "        \n",
    "        Salinas_df4_raw[col+'_'+str(k)+'_prob']=con_re.flatten()\n",
    "        \n",
    "    for col in df5_columns:\n",
    "        print(k,col)\n",
    "\n",
    "        con_var_img=np.zeros((258,110))\n",
    "        con_var_img[1:257,1:109]=Salinas_df5_raw[col].reshape(256,108)\n",
    "        con_re=np.zeros((256,108))\n",
    "        for i in range(1,257):\n",
    "            for j in range(1,109):\n",
    "                con_re[i-1][j-1]=(con_var_img[i-1:i+2,j-1:j+2]*type_prob_m[i-1:i+2,j-1:j+2]).sum()\n",
    "        \n",
    "        Salinas_df5_raw[col+'_'+str(k)+'_prob']=con_re.flatten()\n",
    "#----------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "Salinas_df4_raw=Salinas_df4_raw[Salinas_df4_raw.type!=0]\n",
    "Salinas_df5_raw=Salinas_df5_raw[Salinas_df5_raw.type!=0]\n",
    "Salinas_df4=copy.deepcopy(Salinas_df4_raw)\n",
    "Salinas_df5=copy.deepcopy(Salinas_df5_raw)\n",
    "std=StandardScaler()\n",
    "Salinas_df4.pop('row')\n",
    "Salinas_df4.pop('col')\n",
    "y_train=Salinas_df4.pop('type')\n",
    "x_train=Salinas_df4\n",
    "x_train=std.fit_transform(x_train)\n",
    "Salinas_df5.pop('row')\n",
    "Salinas_df5.pop('col')\n",
    "y_test=Salinas_df5.pop('type')\n",
    "x_test=Salinas_df5\n",
    "x_test=std.fit_transform(x_test)\n",
    "y_true=y_test\n",
    "y_train.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "拟合 逻辑回归 1.0\n",
      "测试 逻辑回归 1.0\n",
      "拟合 梯度提升决策树 1.0\n",
      "测试 梯度提升决策树 1.0\n",
      "拟合 随机森林 1.0\n",
      "测试 随机森林 1.0\n",
      "拟合 决策树 1.0\n",
      "测试 决策树 1.0\n",
      "拟合 K-临近 1.0\n",
      "测试 K-临近 1.0\n",
      "拟合 SVM 1.0\n",
      "测试 SVM 1.0\n",
      "正在输出分类器准确率\n",
      "正在输出kappa系数\n"
     ]
    }
   ],
   "source": [
    "if not (os.path.exists(namespace)):\n",
    "    os.mkdir(namespace)\n",
    "\n",
    "piplines=[LogisticRegression(),GradientBoostingClassifier(),RandomForestClassifier(),DecisionTreeClassifier(),KNeighborsClassifier(),SVC()]\n",
    "pipline_fit_score={'accuracy':[]}\n",
    "pipline_test_score={'accuracy':[]}\n",
    "pipline_fit_test_score={'fit-accuracy':[],'test-accuracy':[]}\n",
    "kappas_={'kappa':[]}\n",
    "\n",
    "clf_names=['逻辑回归','梯度提升决策树','随机森林','决策树','K-临近','SVM']\n",
    "\n",
    "for clf_name,clf in zip(clf_names,piplines):\n",
    "    \n",
    "    \n",
    "    clf.fit(x_train,y_train)\n",
    "    \n",
    "    print('拟合',clf_name,clf.score(x_train,y_train))\n",
    "    \n",
    "    print('测试',clf_name,clf.score(x_test,y_test))\n",
    "    \n",
    "    y_fit_pre=clf.predict(x_train)\n",
    "\n",
    "    y_pre=clf.predict(x_test)\n",
    "    \n",
    "    output(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,y_true,y_pre,y_fit_pre,clf_name)\n",
    "\n",
    "ouput2(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,clf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0\ttest-merror:0\n",
      "[100]\ttrain-merror:0\ttest-merror:0\n",
      "[200]\ttrain-merror:0\ttest-merror:0\n",
      "[300]\ttrain-merror:0\ttest-merror:0\n",
      "[399]\ttrain-merror:0\ttest-merror:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_data_train=xgb.DMatrix(x_train,label=y_train)\n",
    "xgb_data_test=xgb.DMatrix(x_test,label=y_test)\n",
    "params={'max_depth':10,'eta':0.1,'silent':0,'objective':'multi:softmax','num_class':17,'alpha':0.5}\n",
    "bst=xgb.train(params, \n",
    "          xgb_data_train, \n",
    "          num_boost_round=400, \n",
    "          evals=[(xgb_data_train,'train'),(xgb_data_test,'test')], \n",
    "          obj=None, \n",
    "          feval=None, \n",
    "          maximize=False, \n",
    "          early_stopping_rounds=None,\n",
    "          evals_result=None,\n",
    "          verbose_eval=100,\n",
    "          xgb_model=None,\n",
    "          callbacks=None)\n",
    "xgb_data_test=xgb.DMatrix(x_test)\n",
    "y_pre=bst.predict(xgb_data_test)\n",
    "y_true=y_test\n",
    "\n",
    "y_pre=bst.predict(xgb_data_test)\n",
    "y_fit_pre=bst.predict(xgb_data_train)\n",
    "y_true=y_test\n",
    "accuracy_score(y_true,y_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在输出分类器准确率\n",
      "正在输出kappa系数\n"
     ]
    }
   ],
   "source": [
    "clf_name='XGBoost'\n",
    "clf_names.append(clf_name)\n",
    "output(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,y_true,y_pre,y_fit_pre,clf_name)\n",
    "ouput2(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,clf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13490/13490 [==============================] - 6s 411us/step - loss: 0.0250\n",
      "Epoch 2/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 6.4295e-04\n",
      "Epoch 3/50\n",
      "13490/13490 [==============================] - 2s 167us/step - loss: 3.6610e-04\n",
      "Epoch 4/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 2.5258e-04\n",
      "Epoch 5/50\n",
      "13490/13490 [==============================] - 2s 172us/step - loss: 1.9845e-04\n",
      "Epoch 6/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 1.6840e-04\n",
      "Epoch 7/50\n",
      "13490/13490 [==============================] - 2s 169us/step - loss: 1.3947e-04\n",
      "Epoch 8/50\n",
      "13490/13490 [==============================] - 2s 171us/step - loss: 1.2943e-04\n",
      "Epoch 9/50\n",
      "13490/13490 [==============================] - 2s 168us/step - loss: 1.4705e-04\n",
      "Epoch 10/50\n",
      "13490/13490 [==============================] - 2s 173us/step - loss: 1.2092e-04\n",
      "Epoch 11/50\n",
      "13490/13490 [==============================] - 2s 172us/step - loss: 1.0008e-04\n",
      "Epoch 12/50\n",
      "13490/13490 [==============================] - 2s 167us/step - loss: 9.5383e-05\n",
      "Epoch 13/50\n",
      "13490/13490 [==============================] - 2s 168us/step - loss: 8.9414e-05\n",
      "Epoch 14/50\n",
      "13490/13490 [==============================] - 2s 166us/step - loss: 7.9423e-05\n",
      "Epoch 15/50\n",
      "13490/13490 [==============================] - 2s 165us/step - loss: 8.1369e-05\n",
      "Epoch 16/50\n",
      "13490/13490 [==============================] - 2s 171us/step - loss: 9.4704e-05\n",
      "Epoch 17/50\n",
      "13490/13490 [==============================] - 2s 169us/step - loss: 7.0811e-05\n",
      "Epoch 18/50\n",
      "13490/13490 [==============================] - 2s 173us/step - loss: 9.3221e-05\n",
      "Epoch 19/50\n",
      "13490/13490 [==============================] - 2s 171us/step - loss: 6.6515e-05\n",
      "Epoch 20/50\n",
      "13490/13490 [==============================] - 2s 166us/step - loss: 6.0490e-05\n",
      "Epoch 21/50\n",
      "13490/13490 [==============================] - 2s 169us/step - loss: 7.5045e-05\n",
      "Epoch 22/50\n",
      "13490/13490 [==============================] - 2s 172us/step - loss: 6.1451e-05\n",
      "Epoch 23/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 5.5168e-05\n",
      "Epoch 24/50\n",
      "13490/13490 [==============================] - 2s 169us/step - loss: 5.5493e-05\n",
      "Epoch 25/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 6.4659e-05\n",
      "Epoch 26/50\n",
      "13490/13490 [==============================] - 2s 167us/step - loss: 5.3428e-05\n",
      "Epoch 27/50\n",
      "13490/13490 [==============================] - 2s 169us/step - loss: 5.0677e-05\n",
      "Epoch 28/50\n",
      "13490/13490 [==============================] - 2s 168us/step - loss: 5.2349e-05\n",
      "Epoch 29/50\n",
      "13490/13490 [==============================] - 2s 172us/step - loss: 5.3187e-05\n",
      "Epoch 30/50\n",
      "13490/13490 [==============================] - 2s 171us/step - loss: 4.7957e-05\n",
      "Epoch 31/50\n",
      "13490/13490 [==============================] - 2s 167us/step - loss: 4.7405e-05\n",
      "Epoch 32/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 4.6042e-05\n",
      "Epoch 33/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 4.4289e-05\n",
      "Epoch 34/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 4.3477e-05\n",
      "Epoch 35/50\n",
      "13490/13490 [==============================] - 2s 169us/step - loss: 5.2914e-05\n",
      "Epoch 36/50\n",
      "13490/13490 [==============================] - 2s 166us/step - loss: 4.2854e-05\n",
      "Epoch 37/50\n",
      "13490/13490 [==============================] - 2s 171us/step - loss: 3.7886e-05\n",
      "Epoch 38/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 3.7858e-05\n",
      "Epoch 39/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 4.0577e-05\n",
      "Epoch 40/50\n",
      "13490/13490 [==============================] - 2s 171us/step - loss: 3.6908e-05\n",
      "Epoch 41/50\n",
      "13490/13490 [==============================] - 2s 171us/step - loss: 3.6539e-05\n",
      "Epoch 42/50\n",
      "13490/13490 [==============================] - 2s 169us/step - loss: 3.6261e-05\n",
      "Epoch 43/50\n",
      "13490/13490 [==============================] - 2s 171us/step - loss: 7.3895e-05\n",
      "Epoch 44/50\n",
      "13490/13490 [==============================] - 2s 168us/step - loss: 3.6388e-05\n",
      "Epoch 45/50\n",
      "13490/13490 [==============================] - 2s 174us/step - loss: 3.5566e-05\n",
      "Epoch 46/50\n",
      "13490/13490 [==============================] - 2s 170us/step - loss: 3.5504e-05\n",
      "Epoch 47/50\n",
      "13490/13490 [==============================] - 2s 172us/step - loss: 3.5274e-05\n",
      "Epoch 48/50\n",
      "13490/13490 [==============================] - 2s 171us/step - loss: 3.3093e-05\n",
      "Epoch 49/50\n",
      "13490/13490 [==============================] - 2s 169us/step - loss: 3.3924e-05\n",
      "Epoch 50/50\n",
      "13490/13490 [==============================] - 2s 166us/step - loss: 3.3225e-05\n"
     ]
    }
   ],
   "source": [
    "i=6\n",
    "input_dim=x_train.shape[1]\n",
    "output_dim=len(set(y_train.tolist()))\n",
    "batch_size=16\n",
    "lr=0.1\n",
    "epochs=50\n",
    "hidden_num = input_dim*i\n",
    "hidden_num_2 = output_dim*i\n",
    "ohe = OneHotEncoder()\n",
    "y_train=ohe.fit_transform(np.matrix(y_train.values).T).toarray()\n",
    "model=Sequential()\n",
    "model.add(Dense(input_dim=input_dim,units=hidden_num))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(input_dim=hidden_num_2,units=output_dim))\n",
    "optimizer=SGD(lr=lr)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)\n",
    "model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,verbose=1)\n",
    "\n",
    "y_pre=model.predict_classes(x_test, batch_size=batch_size)\n",
    "y_fit_pre=model.predict_classes(x_train, batch_size=batch_size)\n",
    "\n",
    "y_true=y_test\n",
    "y_pre=y_pre+1\n",
    "y_fit_pre=y_fit_pre+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在输出分类器准确率\n",
      "正在输出kappa系数\n"
     ]
    }
   ],
   "source": [
    "clf_name='NN'\n",
    "clf_names.append(clf_name)\n",
    "output(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,y_true,y_pre,y_fit_pre,clf_name)\n",
    "ouput2(pipline_fit_score,pipline_test_score,pipline_fit_test_score,kappas_,clf_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉矩阵(准确率、召回率,F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kappa系数\n",
    "准确率\n",
    "kappa计算结果为-1~1，但通常kappa是落在 0~1 间，可分为五组来表示不同级别的一致性：\n",
    "0.0~0.20极低的一致性(slight)、\n",
    "0.21~0.40一般的一致性(fair)、\n",
    "0.41~0.60 中等的一致性(moderate)、\n",
    "0.61~0.80 高度的一致性(substantial)\n",
    "0.81~1几乎完全一致(almost perfect)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losss下降过程(运算时间)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "错的点的坐标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测值的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络层数图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
